# -*- coding: utf-8 -*-
import os
import re
import scipy.io
import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix, isspmatrix
from anndata import AnnData

from utilities import *

## The LIGER Class
class Liger(object):
    """ Main LIGER class
    
    The liger object is created from two or more single cell datasets. To construct a
    liger object, the user needs to provide at least two expression (or another
    single-cell modality) matrices. The class provides functions for data
    preprocessing, integrative analysis, and visualization.
    
    Args:
        
    Attributes:
        adata_list(list):
            List of AnnData objects, one per experiment/dataset (genes by cells)
            In each AnnData objects, main matrix stores raw data and two addtional
            layers store normalized data and sclaed data with keys norm_data and
            sclae_data respectively.
        cell_data(): 
            Dataframe of cell attributes across all datasets (nrows equal to total number
            cells across all datasets)
        var_genes(): 
            Subset of informative genes shared across datasets to be used in matrix
            factorization
        H(list): 
            Cell loading factors (one matrix per dataset, dimensions cells by k)
        H_norm(): 
            Normalized cell loading factors (cells across all datasets combined into single
            matrix)
        W(): 
            Shared gene loading factors (k by genes)
        V(list): 
            Dataset-specific gene loading factors (one matrix per dataset, dimensions k by genes)
        tsne_coords(): 
            Matrix of 2D coordinates obtained from running t-SNE on H_norm or H matrices
        alignment_clusters(): 
            Initial joint cluster assignments from shared factor alignment
        clusters(): 
            Joint cluster assignments for cells
        snf(list): 
            List of values associated with shared nearest factor matrix for use in clustering and
            alignment (out_summary contains edge weight information between cell combinations)
        agg_data(list): 
            Data aggregated within clusters
        parameters(list): 
            List of parameters used throughout analysis
        version(): 
            Version of package used to create object
    """
    
    __slots__ = ('adata_list', 'cell_data', 'var_genes', 'H', 'H_norm', 'W', 'V', 
                 'tsne_coords', 'alignment_clusters', 'clusters', 'agg_data', 
                 'parameters', 'snf', 'version')
    
    def __init__(self, adata_list):
        self.adata_list = adata_list
        
    """ 
    @property
    def cell_data(self):
        return self._cell_data
    @cell_data.setter
    def cell_data(self, value):
        self.cell_data = value
    """
    def show(self):
        print("An object of class liger with {} datasets and {} total cells.".format(len(self.raw_data),len(self.cell_data)))

   
#######################################################################################
#### Data Preprocessing
   
def read10X(sample_dirs, 
            sample_names, 
            merge = True, 
            num_cells = None, 
            min_umis = 0,
            use_filtered = False, 
            reference = None, 
            data_type = "rna"):
    """ Read 10X alignment data (including V3)    
     
    This function generates a sparse matrix (genes x cells) from the data generated by 10X's
    cellranger count pipeline. It can process V2 and V3 data together, producing either a single
    merged matrix or list of matrices. Also handles multiple data types produced by 10X V3 (Gene
    Expression, Antibody Capture, CRISPR, CUSTOM).
     
    Args:
        sample_dirs(list):
            List of directories containing either matrix.mtx(.gz) file along with genes.tsv,
            (features.tsv), and barcodes.tsv, or outer level 10X output directory (containing outs directory).
        sample_names(list): 
            List of names to use for samples (corresponding to sample_dirs)
        merge(bool): optional, (default True)
            Whether to merge all matrices of the same data type across samples or leave as list
            of matrices.
        num_cells(): optional, (default None)
            Optional limit on number of cells returned for each sample (only for Gene
            Expression data). Retains the cells with the highest numbers of transcripts.
        min_umis(int): optional, (default 0)
            Minimum UMI threshold for cells.
        use_filtered(bool): optional, (default Flase)
            Whether to use 10X's filtered data (as opposed to raw). Only relevant for
            sample.dirs containing 10X outs directory.
        reference(): optional, (default None)
            For 10X V<3, specify which reference directory to use if sample_dir is outer
            level 10X directory (only necessary if more than one reference used for sequencing).
        data_type(str): optional, 'rna' or 'atac', (default 'rna')
            Indicates the protocol of the input data. If not specified, input data will be 
            considered scRNA-seq data. 

    Return:
        datalist(list): 
             List of merged matrices across data types (returns sparse matrix if only one data type
             detected), or nested list of matrices organized by sample if merge=F.
         
    Usage:
         >>> sample_dir1 = "path/to/outer/dir1" # 10X output directory V2 -- contains outs/raw_gene_bc_matrices/<reference>/...
         >>> sample_dir2 = "path/to/outer/dir2" # 10X output directory V3 -- for two data types, Gene Expression and CUSTOM
         >>> dges1 = read10X(list(sample_dir1, sample_dir2), c("sample1", "sample2"), min.umis = 50)
         >>> ligerex = createLiger(expr = dges1[["Gene Expression"]], custom = dges1[["CUSTOM"]])
    """
    datalist = []
    datatypes = np.array(['Gene Expression'])
    
    if num_cells is not None:
        num_cells = np.repeat(num_cells, len(sample_dirs))
    
    for i in range(len(sample_dirs)):
        
        # Start message
        print('Processing sample ' + sample_names[i])
        
        # Construct sample path
        sample_dir = sample_dirs[i]
        inner1 = sample_dir + '/outs'

        if os.path.exists(inner1):
            sample_dir = inner1
            is_v3 = os.path.exists(sample_dir + '/filtered_feature_bc_matrix')
            matrix_prefix = str(np.where(use_filtered, 'filtered', 'raw'))
            if is_v3:
                print('yes')
                sample_dir = sample_dir + '/' + matrix_prefix + '_feature_bc_matrix'
            else:
                if reference is None:
                    references = os.listdir(sample_dir + '/raw_gene_bc_matrices')
                    if len(references) > 1:
                        raise ValueError('Multiple reference genomes found. Please specify a single one.')
                    else:
                        reference = references[0]
            if reference is None:
                reference = ''
            sample_dir = sample_dir + '/' + matrix_prefix + '_gene_bc_matrices/' + reference
        else:
            is_v3 = os.path.exists(sample_dir + '/features.tsv.gz')
        
        suffix = str(np.where(is_v3, '.gz', ''))
        if data_type == 'rna':
            features_file = str(np.where(is_v3, sample_dir + '/features.tsv.gz', sample_dir + '/genes.tsv'))
        elif data_type == 'atac':
            features_file = str(np.where(is_v3, sample_dir + '/peaks.bed.gz', sample_dir + '/peaks.bed'))
        
        matrix_file = sample_dir + '/matrix.mtx' + suffix
        barcodes_file = sample_dir + "/barcodes.tsv" + suffix
        
        # Read in raw data (count matrix)
        rawdata = scipy.io.mmread(matrix_file)
        rawdata = csr_matrix(rawdata) # convert to csr matrix
        
        # filter for UMIs first to increase speed
        umi_pass = np.sum(rawdata, axis=0) > min_umis 
        umi_pass = np.asarray(umi_pass).flatten() # convert to np array
        if len(umi_pass) == 0:
            print('No cells pass UMI cutoff. Please lower it.')
        rawdata = rawdata.toarray()
        rawdata = rawdata[:,umi_pass]
        
        # Read in barcodes
        barcodes = pd.read_csv(barcodes_file, sep='\t', header=None)
        barcodes = barcodes.to_numpy().flatten()[umi_pass]
        
        # remove -1 tag from barcodes
        for i in range(barcodes.size):
            barcodes[i] = re.sub('\-1$', '', barcodes[i])
        
        if data_type == 'rna':
            features = pd.read_csv(features_file, sep='\t', header=None).to_numpy() # convert to np array
            row_names = features[:,1]
            # equal to make.unique function in R
            count_dict = {}
            for i in range(len(row_names)):
                name = row_names[i]
                if name not in count_dict:
                    count_dict[name] = 0
                if name in row_names:
                    count_dict[name] += 1
                    if count_dict[name] > 1:
                        row_names[i] = row_names[i] + '.' + str(count_dict[name]-1)
            
        elif data_type == 'atac':
            features = pd.read_csv(features_file, sep='\t', header=None).to_numpy()
            features = np.array([str(feature[0]) + ':' + str(feature[1]) + '-' + str(feature[2]) for feature in features])
            row_names = features
        
        # since some genes are only differentiated by ENSMBL
        col_names = barcodes
        
        # split based on 10X datatype -- V3 has Gene Expression, Antibody Capture, CRISPR, CUSTOM
        # V2 has only Gene Expression by default and just two columns
        if features.shape[1] == 0:
            sample_name = np.array(['Chromatin Accessibility'])
        elif features.shape[1] < 3:
            sample_name = np.array(['Gene Expression'])
        else:
            sample_datatypes = features[:,2]
            sample_name = np.unique(sample_datatypes)
            # keep track of all unique datatypes
            datatypes = np.union1d(datatypes, sample_name)
            
            samplelist = {}
            for name in datatypes:
                rawdata = rawdata[:,sample_datatypes == name]
        # num_cells filter only for gene expression data
        if num_cells is not None:
            if 'Gene Expression' in sample_name or 'Chromatin Accessibility' in sample_name:
                data_label = sample_name
                cs = 
        
        if merge:
            print('Merging samples')
        else:
            return datalist
        
        # if only one type of data present

        samplelist = pd.DataFrame(data=rawdata, index=row_names, columns=col_names)
        datalist.append(samplelist)
    
        
    return datalist

def createLiger(adata_list, 
                make_sparse = True, 
                take_gene_union = False,
                remove_missing = True):
    """ Create a liger object. 
    
    This function initializes a liger object with the raw data passed in. It requires a list of
    expression (or another single-cell modality) matrices (gene by cell) for at least two datasets.
    By default, it converts all passed data into Compressed Sparse Row matrix (CSR matrix) to reduce 
    object size. It initializes cell_data with nUMI and nGene calculated for every cell.
    
    Args:
        adata_list(list): 
            List of AnnData objects which store expression matrices (gene by cell). 
            Should be named by dataset.
        make_sparse(bool): optional, (default True) 
            Whether to convert raw_data into sparse matrices.
        take_gene_union(bool): optional,  (default False) 
            Whether to fill out raw_data matrices with union of genes across all
            datasets (filling in 0 for missing data) (requires make_sparse=True).
        remove_missing(bool): optional, (default True)
            Whether to remove cells not expressing any measured genes, and genes not
            expressed in any cells (if take_gene_union=True, removes only genes not 
            expressed in any dataset).
        
    Return:
        liger_object(liger): 
            object with raw_data slot set.
    
    Usage:
        >>> adata1 = AnnData(np.arange(12).reshape((4, 3)))
        >>> adata2 = AnnData(np.arange(12).reshape((4, 3)))
        >>> ligerex = createLiger([adata1, adata2])
        
    """ 
    # Make matrix sparse
    if make_sparse:
        for i in range(len(adata_list)):
            if isspmatrix(adata_list[i].X):
                # forse raw data to be csr matrix
                adata_list[i].X = csr_matrix(adata_list[i].X)      
                # check if dimnames exist
                if not adata_list[i].obs_keys() or not adata_list[i].var_keys():
                    raise ValueError('Raw data must have both row (gene) and column (cell) names.')
                # check whether cell name is unique or not
                if adata_list[i].var['cell_name'].shape[0] - np.unique(adata_list[i].var['cell_name']).shape[0] > 0 and raw_data[i].X.shape[0] > 1     
                    raise ValueError('At least one cell name is repeated across datasets; please make sure all cell names are unique.')
            else:
                adata_list[i].X = csr_matrix(adata_list[i].X)        
    
    # Take gene union (requires make_sparse=True)
    if take_gene_union and make_sparse:
        merged_data = MergeSparseDataAll(adata_list)
        if remove_missing:
            missing_genes = np.array(np.sum(merged_data.X, axis=1)).flatten() == 0
            if len(missing_genes) > 0:
                print('Removing {} genes not expressed in any cells across merged datasets.'.format(len(missing_genes)))
                # show gene name when the total of missing genes is less than 25
                if len(missing_genes) < 25:
                    print(merged_data.obs['gene name'][missing_genes])
                # save data after removing missing genes
                merged_data = merged_data[~missing_genes,:].copy()
        # fill out raw_data matrices with union of genes across all datasets
        for i in range(len(adata_list)):
            adata_list[i] = merged_data[:, merged_data.var['barcodes']==adata_list[i].var['barcodes']].copy()
    
    # Create liger object based on raw data list
    liger_object = Liger(adata_list)
    
    # Remove missing cells
    if remove_missing:
        liger_object = removeMissingObs(liger_object, use_cols = True)
        # remove missing genes if not already merged
        if not take_gene_union:
            liger_object = removeMissingObs(liger_object, use_cols = False)
    
    # Initialize cell_data for liger_object with nUMI, nGene, and dataset
    liger_object.cell_data = pd.DataFrame()
    for adata in adata_list:
        temp = pd.DataFrame(index=adata.var['barcodes'])
        temp['nUMI'] = np.array(np.sum(adata.X, axis=0)).flatten()
        temp['nGene'] = np.count_nonzero(adata.X.toarray(), axis=0)
        temp['dataset'] = np.repeat(adata.obs['data type'][0], adata.var['barcodes'].shape[0])
        liger_object.cell_data.append(temp)
    
    return liger_object


def normalize(liger_object):
    """ Normalize raw datasets to column sums
    
    This function normalizes data to account for total gene expression across a cell.
    
    Args:
        liger_object(liger): 
            liger object with raw_data
    
    Return:
        liger_object(liger):
            liger object with norm_data
            
    Usage:
        >>> adata1 = AnnData(np.arange(12).reshape((4, 3)))
        >>> adata2 = AnnData(np.arange(12).reshape((4, 3)))
        >>> ligerex = createLiger([adata1, adata2])
        >>> ligerex = normalize(ligerex)
    """
    liger_object = removeMissingObs(liger_object, slot_use='raw_data', use_cols=True)
    liger_object.norm_data = [csr_matrix(raw_data/np.sum(raw_data, axis=0)) for raw_data in liger_object.raw_data]
    return liger_object


def selectGenes(liger_object,
                var_thresh = 0.1,
                alpha_thresh = 0.99,
                num_genes = None,
                tol = 0.0001,
                datasets_use = None,
                combine = 'union',
                keep_unique = False,
                capitalize = False, 
                do_plot = False,
                cex_use = 0.3):
    """ Select a subset of informative genes
    
    This function identifies highly variable genes from each dataset and combines these gene sets
    (either by union or intersection) for use in downstream analysis. Assuming that gene
    expression approximately follows a Poisson distribution, this function identifies genes with
    gene expression variance above a given variance threshold (relative to mean gene expression).
    It also provides a log plot of gene variance vs gene expression (with a line indicating expected
    expression across genes and cells). Selected genes are plotted in green.
    
    Args:
        liger_object(liger):
            Should have already called normalize.
        var_thresh(float): optional, (default 0.1)
            Variance threshold. Main threshold used to identify variable genes. Genes with
            expression variance greater than threshold (relative to mean) are selected.
            (higher threshold -> fewer selected genes). Accepts single value or vector with separate
            var_thresh for each dataset.
        alpha_thresh(float): optional, (default 0.99)
            Alpha threshold. Controls upper bound for expected mean gene expression
            (lower threshold -> higher upper bound).
        num_genes(): optional, (default=None)
            Number of genes to find for each dataset. Optimises the value of var.thresh
            for each dataset to get this number of genes. Accepts single value or vector with same length
            as number of datasets.
        tol(float): optional, (default 0.0001)
            Tolerance to use for optimization if num.genes values passed in.
        datasets_use(list): optional, (default 1:len(liger_object.raw_data))
            List of datasets to include for discovery of highly variable genes. 
        combine(str): optional, 'union' or 'intersect', (default 'union')
            How to combine variable genes across experiments.
        keep_unique(bool): optional, (default False)
            Keep genes that occur (i.e., there is a corresponding column in raw.data) only
            in one dataset.
        capitalize(bool): optional, (default False)
            Capitalize gene names to match homologous genes (ie. across species)
        do_plot(bool): optional, (default False)
            Display log plot of gene variance vs. gene expression for each dataset.
            Selected genes are plotted in green.
        cex_use(float): optional, (default 0.3)
            Point size for plot.
            
    Return:
        liger_object(liger): 
            Object with var_genes attribute.
            
    Example:
        >>> adata1 = AnnData(np.arange(12).reshape((4, 3)))
        >>> adata2 = AnnData(np.arange(12).reshape((4, 3)))
        >>> ligerex = createLiger([adata1, adata2])
        >>> ligerex = normalize(ligerex)
        >>> ligerex = selectGenes(ligerex) # use default selectGenes settings
        >>> ligerex = selectGenes(ligerex, var_thresh=0.8) # select a smaller subset of genes
    """
    if datasets_use is None:
        datasets_use = range(1,len(liger_object.raw_data))
        
    # Expand if only single var.thresh passed
    var_thresh = np.repeat(var_thresh, len(liger_object.raw_data))
    num_genes = np.repeat(num_genes, len(liger_object.raw_data))
    
    if not :
        datasets_use = 
        
    genes_use = []
    for i in datasets_use:
        if capitalize:
            
        trx_per_cell = 
        # Each gene's mean expression level (across all cells)
        gene_expr_mean = 
        # Each gene's expression variance (across all cells)
        gene_expr_var = 
        
        nolan_constant = 
        alphathresh_corrected = 
        genemeanupper = 
        basegenelower = 
        
        
        
        if num_genes is not None:
        # Optimize to find value of x which gives the desired number of genes for this dataset
        # if very small number of genes requested, var.thresh may need to exceed 1
            from scipy.optimize import minimize
            
        if do_plot:
            
            
        if combine == 'union':
            
        if combine == 'intersect':
            if len(genes_use) == 0:
                genes_use = genes_new
                
            genes_use = 
            
            
        if not keep_unique:
            for i in range(len(liger_object.raw_data)):
                
                
        if len(genes_use == 0):
            
        liger_object.var_genes = genes_use

    return liger_object


def scaleNotCenter(liger_object, 
                   remove_missing = True):
    """ Scale genes by root-mean-square across cells
    
    This function scales normalized gene expression data after variable genes have been selected.
    Note that the data is not mean-centered before scaling because expression values must remain
    positive (NMF only accepts positive values). It also removes cells which do not have any
    expression across the genes selected, by default.
    
    Args:
        liger_object(liger):
            Should call normalize and selectGenes before calling.
        remove_missing(bool): optional, (default True)
            Whether to remove cells from scale_data with no gene expression.
            
    Return:
        liger_object(liger):
            Object with scale_data layer.
            
    Example:
        >>> adata1 = AnnData(np.arange(12).reshape((4, 3)))
        >>> adata2 = AnnData(np.arange(12).reshape((4, 3)))
        >>> ligerex = createLiger([adata1, adata2])
        >>> ligerex = normalize(ligerex)
        >>> ligerex = selectGenes(ligerex) # select genes
        >>> ligerex = scaleNotCenter(ligerex)
    """
    if 
    
    return liger_object


def removeMissingObs(liger_object, 
                     slot_use = "raw_data", 
                     use_cols = True):
    """ Remove cells/genes with no expression across any genes/cells
    
    Removes cells/genes from chosen slot with no expression in any genes or cells respectively.
    
    Args:
        liger_object(liger): 
            object (scale_data or norm_data must be set).
        slot_use(str): optional, 'raw_data' or 'scale_data', (default 'raw_data')
            The data slot to filter.
        use_cols(bool): optional, (default True)
            Treat each column as a cell.
        
    Return:
        liger_object(liger): 
            object with modified raw_data (or chosen slot) (dataset names preserved).
        
    Example:
        >>> ligerex = removeMissingObs(ligerex)
    """
    filter_data = getattr(liger_object, slot_use)
    removed = str(np.where(slot_use in ['raw_data', 'norm_data'] and use_cols == True, 'cells', 'genes'))
    expressed = str(np.where(removed == 'cells', ' any genes', ''))
    
    for i in range(len(filter_data.X)):
        if use_cols:
            missing = np.array(np.sum(filter_data.X, axis=0)).flatten()
        else:
            missing = np.array(np.sum(filter_data.X, axis=1)).flatten()
            
        if len(missing) > 0:
            print('Removing {} not expressing {} in {}.'.format(len(missing), removed, expressed, names(object@raw.data)[x]))
            if use_cols:
                if len(missing) < 25:
                    print()
                subset = 
            else:
                if len(missing) < 25:
                    print()
                subset = 
            
        filter_data = 
    return liger_object


#######################################################################################
#### Factorization

# Perform iNMF on scaled datasets
def optimizeALS_list(liger_object,
                     k,
                     value_lambda = 5.0,
                     thresh = 1e-6,
                     max_iters = 30,
                     nrep = 1,
                     H_init = None,
                     W_init = None,
                     V_init = None,
                     rand_seed = 1,
                     print_obj = False):
    pass


# Perform factorization for new value of k
def optimizeNewK(liger_object, k_new, value_lambda = None, thresh = 1e-4, max_iters = 100,
                 rand_seed = 1):
    pass

# Perform factorization for new data
def optimizeNewData(liger_object, new_data, which_datasets, add_to_existing = True,
                     value_lambda = None, thresh = 1e-4, max_iters = 100):
    pass

# Perform factorization for subset of data
def optimizeSubset(liger_object, cell_subset = None, cluster_subset = None, 
                    value_lambda = None, thresh = 1e-4, max_iters = 100, datasets_scale = None):
    pass

# Perform factorization for new lambda value
def optimizeNewLambda(liger_object, new_lambda, thresh = 1e-4, max_iters = 100, rand_seed = 1):
    pass

# Visually suggest appropriate lambda value
def suggestLambda(liger_object, k, lambda_test = None, rand_seed = 1, num_cores = 1,
                  thresh = 1e-4, max_iters = 100, knn_k = 20, k2 = 500, ref_dataset = None,
                  resolution = 1, gen_new = False, nrep = 1, return_data = False, return_raw = False):
    pass

# Visually suggest appropiate k value
# k_test range is set from 5 to 55
def suggestK(liger_object, k_test = range(5, 55, 5), value_lambda = 5, thresh = 1e-4, max_iters = 100,
             num_cores = 1, rand_seed = 1, gen_new = False, nrep = 1, plot_log2 = True,
             return_data = False, return_raw = False):
    
    pass


#######################################################################################
#### Quantile Alignment/Normalization
    
# Quantile align (normalize) factor loadings
def quantile_norm(liger_object, quantiles = 50, ref_dataset = None, min_cells = 20, knn_k = 20, 
                  dims_use = None, do_center = False, max_sample = 1000, eps = 0.9, refine_knn = True):
    pass

# Louvain algorithm for community detection
def louvainCluster(liger_object, resolution = 1.0, k = 20, prune = 1 / 15, eps = 0.1, nRandomStarts = 10,
                   nIterations = 100, random_seed = 1):
    pass

# Impute the query cell expression matrix
def imputeKNN(liger_object, reference, queries, knn_k = 20, weight = True, norm = True, scale = False):
    pass

# Perform Wilcoxon rank-sum test
def runWilcoxon(liger_object, compare_method, data_use = "all"):
    pass

# Linking genes to putative regulatory elements
def linkGenesAndPeaks(gene_counts, peak_counts, path_to_coords, genes_list = None, dist = "spearman", 
                      alpha = 0.05):
    pass

# Export predicted gene-pair interaction
def makeInteractTrack(corr_mat, genes_list, output_path, path_to_coords):
    pass

# Analyze biological interpretations of metagene
def runGSEA(liger_object, gene_sets = [], mat_w = True, mat_v = 0, custom_gene_sets = []):
    pass


#######################################################################################
#### Dimensionality Reduction
    
# Perform t-SNE dimensionality reduction
def runTSNE(liger_object, dims_use, use_raw = False, use_pca = False, perplexity = 30,
            theta = 0.5, method = "Rtsne", fitsne_path = None, rand_seed = 42):
    dims_use = range(1, len(liger_object.H_norm))
    pass

# Perform UMAP dimensionality reduction
def runUMAP(liger_object, dims_use, use_raw = False, k = 2, distance = "euclidean",
            n_neighbors = 10, min_dist = 0.1, rand_seed = 42):
    dims_use = range(1, len(liger_object.H_norm))
    pass


#######################################################################################
#### Metrics

# Calculate a dataset-specificity score for each factor
def calcDatasetSpecificity(liger_object, dataset1 = None, dataset2 = None, do_plot = True):
    pass

# Calculate agreement metric
def calcAgreement(liger_object, dr_method = "NMF", ndims = 40, k = 15, use_aligned = True,
                  rand_seed = 42, by_dataset = False):
    pass

# Calculate alignment metric
def calcAlignment(liger_object, k = None, rand_seed = 1, cells_use = None, cells_comp = None,
                  clusters_use = None, by_cell = False, by_dataset = False):
    pass

# Calculate alignment for each cluster
def calcAlignmentPerCluster(liger_object, rand_seed = 1, k = None, by_dataset = False):
    pass

# Calculate adjusted Rand index
def calcARI(liger_object, clusters_compare):
    pass

# Calculate purity
def calcPurity(liger_object, classes_compare):
    pass

# Calculate proportion mitochondrial contribution
def getProportionMito(liger_object, use_norm = False):
    pass


#######################################################################################
#### Visualization

# Plot t-SNE coordinates of cells across datasets
def plotByDatasetAndCluster(liger_object, clusters = None, title = None, pt_size = 0.3,
                            text_size = 3, do_shuffle = True, rand_seed = 1,
                            axis_labels = None, do_legend = True, legend_size = 5,
                            return_plots = False):
    pass

# Plot specific feature on t-SNE coordinates
def plotFeature(liger_object, feature, by_dataset = True, discrete = None, title = None, 
                pt_size = 0.3, text_size = 3, do_shuffle = True, rand_seed = 1, do_labels = False,
                axis_labels = None, do_legend = True, legend_size = 5, option = 'plasma', 
                cols_use = None, zero_color = '#F5F5F5', return_plots = False):
    pass

# Plot scatter plots of unaligned and aligned factor loadings
def plotFactors(liger_object, num_genes = 10, cells_highlight = None, plot_tsne = False):
    pass

# Generate word clouds and t-SNE plots
def plotWordClouds(liger_object, dataset1 = None, dataset2 = None, num_genes = 30, min_size = 1,
                   max_size = 4, factor_share_thresh = 10, log_fc_thresh = 1,
                   umi_thresh = 30, frac_thresh = 0, pval_thresh = 0.05,
                   do_spec_plot = True, return_plots = False):
    pass

# Generate t-SNE plots and gene loading plots
def plotGeneLoadings(liger_object, dataset1 = None, dataset2 = None, num_genes_show = 12,
                     num_genes = 30, mark_top_genes = True, factor_share_thresh = 10,
                     log_fc_thresh = 1, umi_thresh = 30, frac_thresh = 0,
                     pval_thresh = 0.05, do_spec_plot = True, max_val = 0.1, pt_size = 0.1,
                     option = "plasma", zero_color = "#F5F5F5", return_plots = False,
                     axis_labels = None, do_title = False):
    pass

# Plot violin plots for gene expression
def plotGeneViolin(liger_object, gene, methylation_indices = None,
                   by_dataset = True, return_plots = False):
    pass

# Plot gene expression on dimensional reduction (t-SNE) coordinates
def plotGene(liger_object, gene, use_raw = False, use_scaled = False, scale_by = 'dataset', 
             log2scale = None, methylation_indices = None, plot_by = 'dataset', 
             set_dr_lims = False, pt_size = 0.1, min_clip = None, max_clip = None, 
             clip_absolute = False, points_only = False, option = 'plasma', cols_use = None, 
             zero_color = '#F5F5F5', axis_labels = None, do_legend = True, return_plots = False):
    pass

# Plot expression of multiple genes
def plotGenes(liger_object, genes):
    pass

# Generate a river (Sankey) plot
def makeRiverplot(liger_object, cluster1, cluster2, cluster_consensus = None, min_frac = 0.05,
                  min_cells = 10, river_yscale = 1, river_lty = 0, river_node_margin = 0.1,
                  label_cex = 1, label_col = "black", lab_srt = 0, river_usr = None,
                  node_order = "auto"):
    pass

#' Plot cluster proportions by dataset
def plotClusterProportions(liger_object, return_plot = False):
    pass

# Plot heatmap of cluster/factor correspondence
def plotClusterFactors(liger_object, use_aligned = False, Rowv = np.nan, Colv = "Rowv", col = None,
                       return_data = False):
    pass

#######################################################################################
#### Marker/Cell Analysis

# Find shared and dataset-specific markers
def getFactorMarkers(liger_object, dataset1 = None, dataset2 = None, factor_share_thresh = 10,
                     dataset_specificity = None, log_fc_thresh = 1, umi_thresh = 30,
                     frac_thresh = 0, pval_thresh = 0.05, num_genes = 30, print_genes = False):
    pass

#######################################################################################
#### Conversion/Transformation

# Create a Seurat object containing the data from a liger object
# TO-DO names function
#def ligerToSeurat(liger_object, nms = names(object@H), renormalize = True, use_liger_genes = True,
#                  by_dataset = False):
#    pass

# Create liger object from one or more Seurat objects
def seuratToLiger(liger_object, combined_seurat = False, names = "use-projects", meta_var = None,
                  assays_use = None, raw_assay = "RNA", remove_missing = True, renormalize = True,
                  use_seurat_genes = True, num_hvg_info = None, use_idents = True, use_tsne = True,
                  cca_to_H = False):
    pass

# Construct a liger object with a specified subset
def subsetLiger(liger_object, clusters_use = None, cells_use = None, remove_missing = True):
    pass

# Construct a liger object organized by another feature
def reorganizeLiger(liger_object, by_feature, keep_meta = True, new_label = "orig.dataset"):
    pass

# Convert older liger object into most current version (based on class definition)
def convertOldLiger(liger_object, override_raw = False):
    pass



